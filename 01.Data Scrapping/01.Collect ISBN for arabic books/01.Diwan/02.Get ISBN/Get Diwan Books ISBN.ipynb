{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90051865",
   "metadata": {},
   "source": [
    "![Diwan logo](https://cairowestmag.com/wp-content/uploads/2017/03/Diwan-Bookstores-Logo.png)\n",
    "\n",
    "# Diwan website books scrapping\n",
    "**Note: All the links were collected on 11-02-2023**\n",
    "\n",
    "In this notebook, we will scrape all the book's ISBN in the diwan website from links that we have collected before in the previous notebooks to be used later to get books information form Goodreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e53c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff43ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('my_books_lib_diwan_arabic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3cae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBNs = {}\n",
    "def collect_books_ISBN(links, thread_number):\n",
    "    for index, link in enumerate(links):\n",
    "        print(f'Thread #{thread_number}: Start Index {index}')\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        try:\n",
    "            ISBN = soup.find('li', class_='isbn').text\n",
    "        except Exception:\n",
    "            continue\n",
    "        ISBNs[link] = ISBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68484946",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = np.array_split(df['Link'], 8) # split my main data frame to 8 data frames (number of threads that I will ran)\n",
    "\n",
    "# start runing the threads and gave each one the df that it will scrape\n",
    "threads = []\n",
    "for i, splited_df in enumerate(dfs):\n",
    "    thread = threading.Thread(target=collect_books_ISBN, kwargs={'links': splited_df, 'thread_number': str(i + 1)})\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both Link and ISBN\n",
    "with open(f'Diwan_books_isbn_links.csv', 'w', encoding='utf-8-sig', newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Link', 'ISBN'])\n",
    "        for link, isbn in ISBNs.items():\n",
    "            writer.writerow([link, isbn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only ISBN\n",
    "with open(f'Diwan_books_only_isbn.csv', 'w', encoding='utf-8-sig', newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['ISBN'])\n",
    "        for link, isbn in ISBNs.items():\n",
    "            writer.writerow([isbn])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
