{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e309c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('good_reads_arabic_books_links.csv')\n",
    "smaller_dfs = np.array_split(df, 10)\n",
    "error_link = []\n",
    "error_number = 0\n",
    "non_found_link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3', \n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:54.0) Gecko/20100101 Firefox/54.0', \n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', \n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/20100101 Firefox/78.0', \n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.1 Safari/605.1.15', \n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36 OPR/43.0.2442.991', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36', \n",
    "    'Mozilla/5.0 (X11; Linux x86_64; rv:95.0) Gecko/20100101 Firefox/95.0', \n",
    "    'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:15.0) Gecko/20100101 Firefox/15.0.1', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0', \n",
    "    'Mozilla/5.0 (Linux; Android 8.0.0; Pixel 2 XL Build/OPD1.170816.004) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Mobile Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36', \n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1 Mobile/15E148 Safari/604.1', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1.2 Safari/605.1.15', \n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36', \n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.109 Safari/537.36', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.7'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aadcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_data(driver, link):\n",
    "    try:\n",
    "        driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": random.choice(USER_AGENTS)})\n",
    "        driver.get(link)\n",
    "        webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "        ButtonElement = driver.find_elements(By.XPATH , '//button[@aria-label=\"Book details and editions\"]')\n",
    "        try:\n",
    "            ButtonElement[0].click()\n",
    "        except Exception:\n",
    "            try:\n",
    "                sleep(3)\n",
    "                ButtonElement[0].click()\n",
    "            except Exception:\n",
    "                non_found_link.append(link)\n",
    "                print(f'-- Not Found link: {link} => Total Not Found {len(non_found_link)}')\n",
    "                return False\n",
    "\n",
    "        sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup =  BeautifulSoup(html, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "        # General Info\n",
    "        goodreads_id = driver.current_url.rsplit('/', 1)[1]\n",
    "\n",
    "        try:\n",
    "            title = soup.find('h1', class_='Text Text__title1').text\n",
    "        except Exception:\n",
    "            title = None\n",
    "\n",
    "        try:\n",
    "            image = soup.find('div', class_='BookCover').find('img').get('src')\n",
    "        except Exception:\n",
    "            image = None\n",
    "\n",
    "        try:\n",
    "            goodreads_link = driver.current_url\n",
    "        except Exception:\n",
    "            goodreads_link = None\n",
    "\n",
    "        try:\n",
    "            publication_info = soup.find('p', {'data-testid': 'publicationInfo'}).text\n",
    "        except Exception:\n",
    "            publication_info = None\n",
    "\n",
    "\n",
    "        # Ratings\n",
    "        rating_div = soup.find('div', class_='BookPageMetadataSection__ratingStats')\n",
    "        try:\n",
    "            number_of_rattings = rating_div.find('span', {'data-testid':'ratingsCount'}).text\n",
    "        except Exception:\n",
    "            number_of_rattings = None\n",
    "\n",
    "        try:\n",
    "            number_of_reviews = rating_div.find('span', {'data-testid':'reviewsCount'}).text\n",
    "        except Exception:\n",
    "            number_of_reviews = None\n",
    "\n",
    "        try:\n",
    "            book_rate = rating_div.find('div', class_='RatingStatistics__rating').text\n",
    "        except Exception:\n",
    "            book_rate = None\n",
    "\n",
    "        try:\n",
    "            number_of_5_stars_rating = soup.find('div', {'class':'RatingsHistogram__labelTotal', 'data-testid': 'labelTotal-5'}).text\n",
    "        except Exception:\n",
    "            number_of_5_stars_rating = None\n",
    "\n",
    "        try:\n",
    "            number_of_4_stars_rating = soup.find('div', {'class':'RatingsHistogram__labelTotal', 'data-testid': 'labelTotal-4'}).text\n",
    "        except Exception:\n",
    "            number_of_4_stars_rating = None\n",
    "\n",
    "        try:\n",
    "            number_of_3_stars_rating = soup.find('div', {'class':'RatingsHistogram__labelTotal', 'data-testid': 'labelTotal-3'}).text\n",
    "        except Exception:\n",
    "            number_of_3_stars_rating = None\n",
    "\n",
    "        try:\n",
    "            number_of_2_stars_rating = soup.find('div', {'class':'RatingsHistogram__labelTotal', 'data-testid': 'labelTotal-2'}).text\n",
    "        except Exception:\n",
    "            number_of_2_stars_rating = None\n",
    "\n",
    "        try:\n",
    "            number_of_1_stars_rating = soup.find('div', {'class':'RatingsHistogram__labelTotal', 'data-testid': 'labelTotal-1'}).text\n",
    "        except Exception:\n",
    "            number_of_1_stars_rating = None\n",
    "\n",
    "\n",
    "        # Author\n",
    "        try:\n",
    "            author_name = soup.find('a', class_='ContributorLink').text\n",
    "        except Exception:\n",
    "            author_name = None\n",
    "\n",
    "        try:\n",
    "            author_link = soup.find('a', class_='ContributorLink').get('href')\n",
    "        except Exception:\n",
    "            author_link = None\n",
    "\n",
    "        try:\n",
    "            author_stats = soup.find('div', class_='AuthorPreview').find('span', class_='Text Text__body3 Text__subdued').text\n",
    "            author_no_of_books = author_stats.split('books')[0]\n",
    "            author_followers = author_stats.split('books')[1]\n",
    "        except Exception:\n",
    "            author_no_of_books = None\n",
    "            author_followers = None\n",
    "\n",
    "\n",
    "        # Book Info\n",
    "        book_info = soup.find_all('div', class_='DescListItem')\n",
    "        original_title = None\n",
    "        book_format = None\n",
    "        published = None\n",
    "        language = None\n",
    "        setting = None\n",
    "        isbn = None\n",
    "        try:\n",
    "            for info in book_info:\n",
    "                if 'Original title' in info.text:\n",
    "                    original_title = info.find('dd').text\n",
    "                elif 'Format' in info.text:\n",
    "                    book_format = info.find('dd').text\n",
    "                elif 'Published' in info.text:\n",
    "                    published = info.find('dd').text\n",
    "                elif 'Language' in info.text:\n",
    "                    language = info.find('dd').text\n",
    "                elif 'Setting' in info.text:\n",
    "                    setting = info.find('dd').text\n",
    "                elif 'ISBN' in info.text:\n",
    "                    isbn = info.find('dd').text\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Contributors\n",
    "        try:\n",
    "            contributors = soup.find('div', class_='ContributorLinksList').find_all('a')\n",
    "            all_contributors = []\n",
    "            for contributor in contributors:\n",
    "                all_contributors.append(contributor.text)\n",
    "            all_contributors = ','.join(all_contributors)\n",
    "        except Exception:\n",
    "            all_contributors = None\n",
    "\n",
    "\n",
    "        # Other Info\n",
    "        try:\n",
    "            number_of_editions = soup.find('div', class_='MoreEditions').find('a', class_='Button Button--inline Button--small').text\n",
    "        except Exception:\n",
    "            number_of_editions = None\n",
    "\n",
    "        try:\n",
    "            currently_reading = soup.find('div', {'data-testid': 'currentlyReadingSignal'}).text\n",
    "        except Exception:\n",
    "            currently_reading = None\n",
    "\n",
    "        try:\n",
    "            to_read = soup.find('div', {'data-testid': 'toReadSignal'}).text\n",
    "        except Exception:\n",
    "            to_read = None\n",
    "\n",
    "        # book genres\n",
    "        try:\n",
    "            genres = soup.find_all('span', class_='BookPageMetadataSection__genreButton')\n",
    "            all_genres = []\n",
    "            for genre in genres:\n",
    "                all_genres.append(genre.text)\n",
    "            all_genres = ','.join(all_genres)\n",
    "        except Exception:\n",
    "            all_genres = None\n",
    "\n",
    "        data = {\n",
    "            'ISBN':isbn,\n",
    "            'goodreads_id':goodreads_id,\n",
    "            'title':title,\n",
    "            'image':image,\n",
    "            'goodreads_link':goodreads_link,\n",
    "            'publication_info':publication_info,\n",
    "            'number_of_rattings':number_of_rattings,\n",
    "            'number_of_reviews':number_of_reviews,\n",
    "            'book_rate':book_rate,\n",
    "            'number_of_5_stars_rating':number_of_5_stars_rating,\n",
    "            'number_of_4_stars_rating':number_of_4_stars_rating,\n",
    "            'number_of_3_stars_rating':number_of_3_stars_rating,\n",
    "            'number_of_2_stars_rating':number_of_2_stars_rating,\n",
    "            'number_of_1_stars_rating':number_of_1_stars_rating,\n",
    "            'author_name':author_name,\n",
    "            'author_link':author_link,\n",
    "            'author_no_of_books':author_no_of_books,\n",
    "            'author_followers':author_followers,\n",
    "            'original_title':original_title,\n",
    "            'book_format':book_format,\n",
    "            'published':published,\n",
    "            'language':language,\n",
    "            'setting':setting,\n",
    "            'all_contributors':all_contributors,\n",
    "            'number_of_editions':number_of_editions,\n",
    "            'currently_reading':currently_reading,\n",
    "            'to_read':to_read,\n",
    "            'all_genres':all_genres\n",
    "        }\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        global error_number\n",
    "        error_number += 1\n",
    "        print('#' * 50)\n",
    "        print(f'------ New Error #{error_number} -  link: {link} - Error: {e}')\n",
    "        print('#' * 50)\n",
    "        error_data= {link: e}\n",
    "        error_link.append(error_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_scraping(link_all, thread_number, df_index):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "    chrome_options.add_argument(\"--nogpu\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1280,1280\")\n",
    "    chrome_options.add_argument(\"--enable-javascript\")\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "    \n",
    "    # create a new csv per thread to add my data to\n",
    "    csv_file = open(f'data/goodreads_{df_index}_{thread_number}.csv', 'a+', encoding=\"utf-16\")\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=['ISBN', 'goodreads_id', 'title', 'image', 'goodreads_link', 'publication_info', 'number_of_rattings', 'number_of_reviews', 'book_rate', 'number_of_5_stars_rating', 'number_of_4_stars_rating', 'number_of_3_stars_rating', 'number_of_2_stars_rating', 'number_of_1_stars_rating', 'author_name', 'author_link', 'author_no_of_books', 'author_followers', 'original_title', 'book_format', 'published', 'language', 'setting', 'all_contributors', 'number_of_editions', 'currently_reading', 'to_read', 'all_genres'], delimiter ='~')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    all_link_num = len(link_all)\n",
    "    for index, link in enumerate(link_all):\n",
    "        print(f'DF Index {df_index + 1} - Thread #{thread_number}: Start {index + 1}/{all_link_num}')\n",
    "        book_data = get_book_data(driver, link)\n",
    "        if book_data:\n",
    "            writer.writerow(book_data)\n",
    "    print('*' * 100)\n",
    "    print(f'Thread #{thread_number} finshed')\n",
    "    print('*' * 100)\n",
    "    driver.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2315fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_index, smaller_df in enumerate(smaller_dfs):\n",
    "    splited_df = np.array_split(smaller_df, 5) # split my main data frame to 16 data frames (number of threads that I will ran)\n",
    "\n",
    "    # start runing the threads and gave each one the df that it will scrape\n",
    "    threads = []\n",
    "    for i, new_df in enumerate(splited_df):\n",
    "        thread = threading.Thread(target=start_scraping, kwargs={'link_all': new_df['Link'], 'thread_number': str(i + 1), 'df_index':df_index})\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02994da7",
   "metadata": {},
   "source": [
    "#### Join them in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ecb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(10):\n",
    "    for j in range(1,6):\n",
    "        df = pd.read_csv(f'data/goodreads_{i}_{j}.csv', delimiter='~', encoding='utf-16')\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a316436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('goodreads_part_2.csv', encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac1674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
